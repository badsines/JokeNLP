{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jokes - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_json\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "df = read_json(\"reddit_jokes.json\")\n",
    "sentences = df['title'] + ' ' + df['body']\n",
    "# this analyzer from sklearn tokenizes including stop words and lower case\n",
    "analyze = CountVectorizer(stop_words='english').build_analyzer()\n",
    "sentences = [analyze(s) for s in sentences.tolist()]\n",
    "# this trains a cbow on sentences\n",
    "model = word2vec.Word2Vec(sentences, size=200, min_count=10, workers=4)\n",
    "model.wv.save('reddit_jokes.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the non-trainable part of the model from disk\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load('reddit_jokes.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top-N most similar words. Positive words contribute positively towards the similarity, negative words negatively.\n",
    "\n",
    "This method computes cosine similarity between a simple mean of the projection weight vectors of the given words and the vectors for each word in the model. The method corresponds to the word-analogy and distance scripts in the original word2vec implementation.word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "\n",
    "https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.6105002164840698),\n",
       " (u'elizabeth', 0.5213695168495178),\n",
       " (u'arthur', 0.5139883160591125),\n",
       " (u'birbal', 0.48841536045074463),\n",
       " (u'luther', 0.47155600786209106),\n",
       " (u'kings', 0.4652478098869324),\n",
       " (u'prince', 0.4599927067756653),\n",
       " (u'beauty', 0.45947694778442383),\n",
       " (u'lancelot', 0.45744192600250244),\n",
       " (u'kingdom', 0.4568806290626526)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of our vectorization of \"king\" (compare to the ctor for Word2Vec): 200\n",
      "First 12 features of \"king\":  [-0.6883691   0.67239344  0.32713991  1.13332927 -1.23587859  0.36572456\n",
      "  0.67006564  0.68441105  0.45967817  0.11077337 -0.01992935 -1.41261697]\n",
      "The vocabulary is stored as a standard <type 'dict'> of len 20012\n",
      "There is also a <type 'list'>, also of len 20012\n",
      "Here are the first 10 entries:  [u'man', u'says', u'said', u'did', u'like', u'just', u'don', u'know', u'guy', u'asks']\n"
     ]
    }
   ],
   "source": [
    "# Show me the vectorization of the word 'king'\n",
    "vKing = word_vectors['king']\n",
    "print ('Length of our vectorization of \"king\" (compare to the ctor for Word2Vec): {}'.format(len(vKing)))\n",
    "print ('First 12 features of \"king\":  {}'.format(vKing[:12]))\n",
    "# Show me the vocabulary itself\n",
    "print ('The vocabulary is stored as a standard {} of len {}'.format(type(word_vectors.vocab), len(word_vectors.vocab)))\n",
    "print ('There is also a {}, also of len {}'.format(type(word_vectors.index2word), len(word_vectors.index2word)))\n",
    "print ('Here are the first 10 entries:  {}'.format(word_vectors.index2word[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
