{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_json\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "df = read_json(\"reddit_jokes.json\")\n",
    "sentences = df['title'] + ' ' + df['body']\n",
    "# this analyzer from sklearn tokenizes including stop words and lower case\n",
    "analyze = CountVectorizer(stop_words='english').build_analyzer()\n",
    "sentences = [analyze(s) for s in sentences.tolist()]\n",
    "# this trains a cbow on sentences\n",
    "model = word2vec.Word2Vec(sentences, size=100, min_count=10, workers=4)\n",
    "model.wv.save('reddit_jokes.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the non-trainable part of the model from disk\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load('reddit_jokes.model')\n",
    "google_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some similarity comparisons between Google's massive model and ours.  Ours does surprisingly well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "most_similar(positive=['king'])\n",
      "Trained by Jokes\tTrained by Google\n",
      "queen\t0.74\t\tkings\t0.71\n",
      "arthur\t0.72\t\tqueen\t0.65\n",
      "lancelot\t0.65\t\tmonarch\t0.64\n",
      "kings\t0.65\t\tcrown_prince\t0.62\n",
      "================================================================================\n",
      "most_similar(positive=['king','woman'])\n",
      "Trained by Jokes\tTrained by Google\n",
      "queen\t0.63\t\tman\t0.66\n",
      "arthur\t0.57\t\tqueen\t0.64\n",
      "beauty\t0.55\t\tgirl\t0.61\n",
      "bodyguard\t0.53\t\tprincess\t0.61\n",
      "================================================================================\n",
      "most_similar(positive=['king','woman'], negative=['man'])\n",
      "Trained by Jokes\tTrained by Google\n",
      "queen\t0.65\t\tqueen\t0.71\n",
      "elizabeth\t0.59\t\tmonarch\t0.62\n",
      "birbal\t0.57\t\tprincess\t0.59\n",
      "arthur\t0.55\t\tcrown_prince\t0.55\n",
      "================================================================================\n",
      "most_similar(positive=['man'])\n",
      "Trained by Jokes\tTrained by Google\n",
      "mans\t0.67\t\twoman\t0.77\n",
      "gentleman\t0.66\t\tboy\t0.68\n",
      "guy\t0.66\t\tteenager\t0.66\n",
      "woman\t0.62\t\tteenage_girl\t0.61\n",
      "================================================================================\n",
      "most_similar(positive=['woman'])\n",
      "Trained by Jokes\tTrained by Google\n",
      "lady\t0.75\t\tman\t0.77\n",
      "man\t0.62\t\tgirl\t0.75\n",
      "women\t0.62\t\tteenage_girl\t0.73\n",
      "gentleman\t0.58\t\tteenager\t0.63\n"
     ]
    }
   ],
   "source": [
    "#w = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "#g = google_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "def Display(s):\n",
    "    w = eval('word_vectors.' + s)\n",
    "    g = eval('google_vectors.' + s)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    print ('{}'.format(s))\n",
    "    print('Trained by Jokes\\tTrained by Google')\n",
    "    for i in range(4):  #range(len(w)):\n",
    "        print(\"{}\\t{:4.2}\\t\\t{}\\t{:4.2}\".format(w[i][0], w[i][1], g[i][0], g[i][1]))\n",
    "tests = [\"most_similar(positive=['king'])\", \n",
    "         \"most_similar(positive=['king','woman'])\",\n",
    "         \"most_similar(positive=['king','woman'], negative=['man'])\",\n",
    "         \"most_similar(positive=['man'])\",\n",
    "         \"most_similar(positive=['woman'])\",\n",
    "        ]\n",
    "for s in tests:\n",
    "    print('='*80)\n",
    "    Display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of our vectorization of \"king\" (compare to the ctor for Word2Vec): 100\n",
      "First 12 features of \"king\":  [-1.53627563 -1.44087207  0.02402437  1.61712003 -0.89577299 -0.04609798\n",
      " -1.54079127  1.01438117  0.84849453  0.80059016  1.14108241 -1.77830291]\n",
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n",
      "man, 1.98347747326, 1.96043431759, \n",
      "says, 1.17057991028, 0.387207120657, \n",
      "said, 1.29437792301, -1.11761200428, \n",
      "did, -0.731746554375, -1.54007816315, \n",
      "like, 0.520845174789, -0.422606885433, \n",
      "just, 0.421174943447, 2.01930809021, \n",
      "don, -0.217230424285, 1.85953974724, \n",
      "know, 2.2788233757, 0.290828645229, \n",
      "guy, 2.4918589592, 2.01255893707, \n",
      "asks, 2.19117808342, 0.256881028414, \n",
      "The vocabulary is stored as a standard <type 'dict'> of len 20012\n",
      "There is also a <type 'list'>, also of len 20012\n",
      "Here are the first 10 entries:  [u'man', u'says', u'said', u'did', u'like', u'just', u'don', u'know', u'guy', u'asks']\n"
     ]
    }
   ],
   "source": [
    "# Show me the vectorization of the word 'king'\n",
    "vKing = word_vectors['king']\n",
    "print ('Length of our vectorization of \"king\" (compare to the ctor for Word2Vec): {}'.format(len(vKing)))\n",
    "print ('First 12 features of \"king\":  {}'.format(vKing[:12]))\n",
    "# Show me the vocabulary itself# Export to CSV?  Real close here but I don't think we want to go this way.\n",
    "# Instead, use the gensim API / \"KeyedVector\" (word_vector here).\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "print(type(word_vectors))\n",
    "dump_embedding()\n",
    "print ('The vocabulary is stored as a standard {} of len {}'.format(type(word_vectors.vocab), len(word_vectors.vocab)))\n",
    "print ('There is also a {}, also of len {}'.format(type(word_vectors.index2word), len(word_vectors.index2word)))\n",
    "print ('Here are the first 10 entries:  {}'.format(word_vectors.index2word[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke-trained, near woman?\n",
      "[(u'man', 0.8185614347457886), (u'gentleman', 0.5897939205169678), (u'woman', 0.5865741968154907), (u'mans', 0.5807508230209351), (u'lady', 0.5801395177841187), (u'businessman', 0.5530569553375244), (u'guy', 0.5443193912506104), (u'husband', 0.4750097990036011), (u'madam', 0.47310683131217957), (u'smiles', 0.4672502279281616)]\n",
      "Google-trained, near woman?\n",
      "[(u'woman', 0.718680202960968), (u'man', 0.6557512283325195), (u'girl', 0.5882835388183594), (u'lady', 0.5754351615905762), (u'teenage_girl', 0.5700528621673584), (u'teenager', 0.5378326177597046), (u'schoolgirl', 0.497780978679657), (u'policewoman', 0.49065014719963074), (u'blonde', 0.4870774447917938), (u'redhead', 0.4778464436531067)]\n"
     ]
    }
   ],
   "source": [
    "femininity = word_vectors['king'] - word_vectors['queen']\n",
    "near_woman = word_vectors['man'] - femininity\n",
    "print('Joke-trained, near woman?')\n",
    "print(word_vectors.most_similar(positive=[near_woman]))\n",
    "\n",
    "femininity = google_vectors['king'] - google_vectors['queen']\n",
    "near_woman = google_vectors['man'] - femininity\n",
    "print('Google-trained, near woman?')\n",
    "print(google_vectors.most_similar(positive=[near_woman]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'word_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-735bb91a9bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mdoc2avgcbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reddit_jokes.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cbow'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavg_cbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-735bb91a9bd7>\u001b[0m in \u001b[0;36mavg_cbow\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mdoc2avgcbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reddit_jokes.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cbow'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavg_cbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-735bb91a9bd7>\u001b[0m in \u001b[0;36mdoc2avgcbow\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print('   {}'.format(token))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mN\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mavg_cbow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'word_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from pandas import read_json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def doc2avgcbow(sentence):\n",
    "    # this analyzer from sklearn tokenizes including stop words and lower case\n",
    "    analyze = CountVectorizer(stop_words='english').build_analyzer()\n",
    "    tokens = analyze(sentence)\n",
    "    avg_cbow = np.zeros(100)\n",
    "    N = 0\n",
    "    for token in tokens:\n",
    "        #print('   {}'.format(token))\n",
    "        if token in word_vectors.vocab:\n",
    "            N += 1\n",
    "            avg_cbow += word_vectors[token]\n",
    "    if N != 0:\n",
    "        # Some jokes contain nothing in our vocabulary.  Examples.\n",
    "        #  What do you call a shart? Woopsie Poopsie :) \n",
    "        # 1 2 3 4 5 6\n",
    "        # Who do you call when a sleepwalker injures himself? The somnambulance.\n",
    "        avg_cbow = avg_cbow/float(N)\n",
    "    return avg_cbow\n",
    "\n",
    "def avg_cbow():\n",
    "    sentences = df['title'] + ' ' + df['body']\n",
    "    for s in sentences:\n",
    "        yield doc2avgcbow(s)\n",
    "df = read_json(\"reddit_jokes.json\")\n",
    "df['cbow'] = [f for f in avg_cbow()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, score 0.669373698954\n",
      "       meh    liked  \n",
      "meh      24967  11915\n",
      "liked      950   1079\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        meh       0.08      0.53      0.14      2029\n",
      "      liked       0.96      0.68      0.80     36882\n",
      "\n",
      "avg / total       0.92      0.67      0.76     38911\n",
      "\n",
      "DecisionTree, score 0.890442291383\n",
      "       meh    liked  \n",
      "meh      34390   2492\n",
      "liked     1771    258\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        meh       0.09      0.13      0.11      2029\n",
      "      liked       0.95      0.93      0.94     36882\n",
      "\n",
      "avg / total       0.91      0.89      0.90     38911\n",
      "\n",
      "SVC(kernel='linear', C=0.025), score 0.947855362237\n",
      "       meh    liked  \n",
      "meh      36882      0\n",
      "liked     2029      0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        meh       0.00      0.00      0.00      2029\n",
      "      liked       0.95      1.00      0.97     36882\n",
      "\n",
      "avg / total       0.90      0.95      0.92     38911\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msr/.virtualenvs/lab/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(gamma=2, C=1), score 0.946133484105\n",
      "       meh    liked  \n",
      "meh      36738    144\n",
      "liked     1952     77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        meh       0.35      0.04      0.07      2029\n",
      "      liked       0.95      1.00      0.97     36882\n",
      "\n",
      "avg / total       0.92      0.95      0.93     38911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X = df['cbow']\n",
    "# our EDA revealed that a score of > 250 is about the top 5% of all scores.\n",
    "# we'll train to find those.\n",
    "labels = ['meh', 'liked']\n",
    "y = pd.cut(df.score, [0, 250, 100000], include_lowest=True, labels=labels)\n",
    "#y = pd.cut(df.score, 3, labels=['low', 'med', 'high'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "for clf, name in [\n",
    "                  (GaussianNB(), \"Naive Bayes\"), \n",
    "                  (DecisionTreeClassifier(), \"DecisionTree\"), #fast\n",
    "                  (SVC(kernel=\"linear\", C=0.025), \"SVC(kernel='linear', C=0.025)\"), #high score, long time\n",
    "                  (SVC(gamma=2, C=1), \"SVC(gamma=2, C=1)\") # very long time.\n",
    "                 ]:\n",
    "    clf.fit(X_train.tolist(), y_train.tolist())\n",
    "    score = clf.score(X_test.tolist(), y_test.tolist())\n",
    "    y_pred = clf.predict(X_test.tolist())\n",
    "    con_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    print('{}, score {}'.format(name, score))\n",
    "    for l in [' '] + labels:\n",
    "        print('{:7}'.format(l), end='')\n",
    "    print('')\n",
    "    for i,r in enumerate(con_mat):\n",
    "        print('{:7}'.format(labels[i]), end='')\n",
    "        for e in r:\n",
    "            print('{:7}'.format(e), end='')\n",
    "        print('')    \n",
    "    print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
